{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKqoxvprcmdDz82jDO9G9G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ridvanyigit/PyTorch/blob/main/PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cheat Sheet of Top Useful **PyThorch** Methods"
      ],
      "metadata": {
        "id": "XLDbDus6C_p3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "PX_5BMH1GBwO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.tensor\n",
        "* Description : The torch.tensor method used to create a tensor from data. It's one of the most fundamental operations in PyTorch"
      ],
      "metadata": {
        "id": "lXPDydmDDx3K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIwITd1ACu90",
        "outputId": "9ed06526-68e4-43af-c823-00066141136e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Create a tensor from a list\n",
        "data = [1,2,3,4]\n",
        "tensor = torch.tensor(data)\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## torch.zeros\n",
        "* Description : The torch.zeros method returns a tensor filled with zeros. The shape of tensor is defined by the input arguments."
      ],
      "metadata": {
        "id": "jnYIsWMsGUKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 2x3 tensor filled with zeros\n",
        "zeros_tensor = torch.zeros(2,3)\n",
        "zeros_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dakjmVtIGJ_q",
        "outputId": "898da75e-bfab-442a-a4d7-05c693b7c7d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.ones\n",
        "* Description : The torch.ones method returns a tensor filled with ones. The shape of tensor is defined by the input arguments."
      ],
      "metadata": {
        "id": "Tn4l95ILHhM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 2x3 tensor filled with ones\n",
        "ones_tensor = torch.ones(2,3)\n",
        "ones_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWqVzUnOHeI1",
        "outputId": "21f184c2-4149-4b9e-eda0-cfa2ed5d4a06"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.rand\n",
        "* Description : The torch.rand method returns a tensor filled with random numbers between 0 and 1"
      ],
      "metadata": {
        "id": "y16nVremIbY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 3x3 tensor filled with random numbers between 0 and 1\n",
        "rand_tensor = torch.rand(3,3)\n",
        "rand_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ealm6PXIGLS",
        "outputId": "3ed290a7-59fe-4ad7-bbde-2a140f13172d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2979, 0.0876, 0.2316],\n",
              "        [0.6530, 0.7034, 0.7121],\n",
              "        [0.3448, 0.3924, 0.6140]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.randn\n",
        "* Description : The torch.rand method returns a tensor filled with random numbers from a normal distribution"
      ],
      "metadata": {
        "id": "RQlnD9kBJUHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 2x3 tensor filled with random numbers from a normal distribution\n",
        "randn_tensor = torch.randn(2,3)\n",
        "randn_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDSVKWXZJKaj",
        "outputId": "03135c0d-06d2-4e72-a9e0-e2a8cad8d762"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5468, -0.0509, -0.1833],\n",
              "        [-0.1048, -0.1554, -0.9786]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.linspace\n",
        "* Distribution : The torch.linspace method retuns a 1D tensor with values spaced linearly within a given interval"
      ],
      "metadata": {
        "id": "biEoALSuKDez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with 5 values spaced linearly between 0 and 10\n",
        "linspace_tensor = torch.linspace(0, 10, steps=5)\n",
        "linspace_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnCYmzahKAOR",
        "outputId": "2a96de8f-8c6b-4901-9f98-c70387d46ead"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.arange\n",
        "* Description : The torch.arange method returns a 1D tensor with values spaced by a given step size"
      ],
      "metadata": {
        "id": "VVXzNbW_LEFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with values from 0 to 10 with a step size of 2\n",
        "arange_tensor = torch.arange(0, 10, step=2)\n",
        "arange_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZZ2nwe9Kzrh",
        "outputId": "dd3c942c-0229-42b3-d002-fc259f1222f2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 2, 4, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.eye\n",
        "* Description : The torch.eye method returns a 2D tensor with ones on the diagonal and zeros elsewhere (an identity matrix)"
      ],
      "metadata": {
        "id": "2JtnTffZLzoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 3x3 identity matrix\n",
        "eye_tensor = torch.eye(3)\n",
        "eye_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwphBf1GLw7q",
        "outputId": "719239f1-35a5-40a2-a094-18f2b489ff34"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.matmul\n",
        "* Description : The torch.matmul method performs matrix multiplication between two tensors"
      ],
      "metadata": {
        "id": "9bqVrXaiMdUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two 2D tensors\n",
        "tensor1 = torch.tensor([[1,2],[3,4]])\n",
        "tensor2 = torch.tensor([[5,6],[7,8]])\n",
        "\n",
        "# Perform matrix multiplication\n",
        "matmul_result = torch.matmul(tensor1,tensor2)\n",
        "matmul_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v759bhCAMcKx",
        "outputId": "b6295718-7c43-4058-e3b0-9c77394a2e02"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[19, 22],\n",
              "        [43, 50]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.mm\n",
        "* Description : The torch.mm method is similar to torch.matmul, but specifically for 2D tensors"
      ],
      "metadata": {
        "id": "cndiUe4TN3Jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two 2D tensors\n",
        "tensor1 = torch.tensor([[1,2],[3,4]])\n",
        "tensor2 = torch.tensor([[5,6],[7,8]])\n",
        "\n",
        "# Perform matrix multiplication\n",
        "mm_result = torch.mm(tensor1,tensor2)\n",
        "mm_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUN2AOaXNSic",
        "outputId": "19095989-de03-43e4-860f-15c276727d85"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[19, 22],\n",
              "        [43, 50]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.bmm\n",
        "* Description : The torch.bmm method performs batch matrix multiplication"
      ],
      "metadata": {
        "id": "UN6vl4hcOc1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two 3D tensors\n",
        "tensor1 = torch.randn(10, 3, 4)\n",
        "tensor2 = torch.randn(10, 4, 5)\n",
        "\n",
        "# Perform batch matrix multiplication\n",
        "bmm_result = torch.bmm(tensor1, tensor2)\n",
        "bmm_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiqDrLy8Oob9",
        "outputId": "1fcc036d-a227-4b09-8943-b0f79d140909"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1233, -1.0812, -1.6761,  2.2863,  2.1215],\n",
              "         [ 0.1125,  0.3183,  0.9591,  0.4328, -1.0418],\n",
              "         [ 1.5182, -1.6515, -1.4561, -2.3375, -1.3022]],\n",
              "\n",
              "        [[ 0.0670,  0.6765, -0.3750,  1.4633, -1.6344],\n",
              "         [ 1.0787, -0.4239,  0.4056, -3.6803,  1.0330],\n",
              "         [ 0.8893, -1.5297,  2.2400, -2.7689, -1.7993]],\n",
              "\n",
              "        [[ 0.5919,  0.7290, -0.7223,  2.0388,  1.2171],\n",
              "         [-0.2954, -1.4657, -0.9653,  0.8342,  0.7763],\n",
              "         [ 0.5102,  0.0721, -1.3102,  2.9845, -2.0000]],\n",
              "\n",
              "        [[ 0.1626,  1.2960,  1.0410,  0.2144, -0.9684],\n",
              "         [-1.1223, -0.1140, -0.1872, -0.5601, -0.4452],\n",
              "         [-0.4820,  2.7764,  2.3345,  0.6487,  0.4280]],\n",
              "\n",
              "        [[-0.2534, -1.4942, -4.3620,  3.9280,  3.5845],\n",
              "         [ 1.2017, -0.7696, -1.5643,  0.9957,  1.0627],\n",
              "         [-2.4893,  0.0669,  1.9810, -0.7139, -1.0233]],\n",
              "\n",
              "        [[-4.7130, -2.8648, -1.0848,  0.4785,  0.5026],\n",
              "         [-2.6835, -1.6699, -0.8045,  1.7950, -0.3130],\n",
              "         [-4.0427, -3.3244, -2.4697, -1.1951, -3.6832]],\n",
              "\n",
              "        [[ 0.2155,  7.5741, -4.4352, -2.9754,  7.5809],\n",
              "         [ 0.7303, -0.0654, -0.8834,  1.4928,  0.1708],\n",
              "         [-1.6294, -1.4031, -3.4425, -0.7737,  0.9016]],\n",
              "\n",
              "        [[-4.1989, -1.2575, -1.6229,  2.0570, -0.3230],\n",
              "         [-2.6199,  0.6279, -1.7330,  1.8604, -1.6547],\n",
              "         [ 1.2940, -1.1677,  2.2411,  2.9065,  0.0778]],\n",
              "\n",
              "        [[ 1.8230, -1.1297, -0.6707, -0.8092,  0.3518],\n",
              "         [-1.9045,  1.6310,  2.5121, -0.1814, -0.9440],\n",
              "         [-0.4455,  0.7101,  0.2521, -1.8524,  2.8119]],\n",
              "\n",
              "        [[ 0.5774,  0.7507, -1.3482, -2.6029, -1.0492],\n",
              "         [ 0.6404, -0.0742, -0.3093, -0.8073, -1.0464],\n",
              "         [ 0.9078,  2.1113,  2.5308,  0.9771,  2.3682]]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.cat\n",
        "* Desription : The torch.cat method concatenates a sequence of tensors along a specified dimension"
      ],
      "metadata": {
        "id": "fmCVfLefPTrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two tensors\n",
        "tensor1 = torch.tensor([[1,2],[3,4]])\n",
        "tensor2 = torch.tensor([[5,6]])\n",
        "\n",
        "# Concatenate alonge the first dimension\n",
        "cat_result = torch.cat((tensor1, tensor2), dim=0)\n",
        "cat_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrVRBsPKPHIy",
        "outputId": "e3831c60-9156-4145-9d78-c49e2c337f2d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.stack\n",
        "* Description : The torch.stack method stacks a sequence of tensors alonge a new dimension"
      ],
      "metadata": {
        "id": "R-ygQemAQeep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two tensors\n",
        "tensor1 = torch.tensor([1,2])\n",
        "tensor2 = torch.tensor([3,4])\n",
        "\n",
        "# Stack alonge a new dimension\n",
        "stack_result = torch.stack((tensor1, tensor2), dim=0)\n",
        "stack_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdfFwXr4QOjH",
        "outputId": "9329b251-bcfd-46a4-d84c-12c8ec15d827"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.split\n",
        "* Description : The torch.split method splits a tensor into chunks"
      ],
      "metadata": {
        "id": "84ue5LtiRVIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two tensors\n",
        "tensor1 = torch.tensor([1,2,3,4,5,6])\n",
        "\n",
        "# Split into three chunks\n",
        "split_result = torch.split(tensor, 2)\n",
        "for chunk in split_result:\n",
        "  print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKt6VDDaRGq6",
        "outputId": "af20d4a0-930b-401a-d883-ee509ddf341e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2])\n",
            "tensor([3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.chunk\n",
        "* Description : The torch.chunk method splits a tensor into a specified number of chunks"
      ],
      "metadata": {
        "id": "nSLLol1lSUvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two tensors\n",
        "tensor1 = torch.tensor([1,2,3,4,5,6])\n",
        "\n",
        "# Chunk the tensor into three parts\n",
        "chunk_result = torch.chunk(tensor, 3)\n",
        "for chunk in chunk_result:\n",
        "  print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRy-H8bISFNV",
        "outputId": "5c59e802-a121-420c-d9ef-d5574f4d2886"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2])\n",
            "tensor([3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.reshape\n",
        "* Description : The torch.reshape method returns a tensor with a new shape, without changing the data"
      ],
      "metadata": {
        "id": "toOP_bScTHrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tensor\n",
        "tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
        "\n",
        "# Reshape the tensor to a different shape\n",
        "reshape_result = torch.reshape(tensor, (3,2))\n",
        "reshape_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXMYzYOWTHEu",
        "outputId": "93adf827-fc5b-4648-c1d7-24059c429b80"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tensor.view\n",
        "* Description : The tensor.view method returns a new tensor with the same data but a different shape"
      ],
      "metadata": {
        "id": "0OFOqnmrT5M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tensor\n",
        "tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
        "\n",
        "# View the tensor with a different shape\n",
        "view_result = tensor.view(3,2)\n",
        "view_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN0rRoBuT3L-",
        "outputId": "7c10bb18-6c7d-4efb-c275-a2f4e3c460d7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.transpose\n",
        "* Description : The torch.transpose method returns a tensor with dimensions transposed"
      ],
      "metadata": {
        "id": "Wv24l8ZfVDgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tensor\n",
        "tensor = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
        "\n",
        "# Transpose the tensor\n",
        "transpose_result = torch.transpose(tensor, 0, 1)\n",
        "transpose_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9LxbzXEUNpa",
        "outputId": "7c8b891a-3c68-40ca-9a91-a44482357ad2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4, 7],\n",
              "        [2, 5, 8],\n",
              "        [3, 6, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.t\n",
        "* Description : The torch.t method transposes the last two dimensions of a tensor"
      ],
      "metadata": {
        "id": "ERfMDZ_1ViCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tensor\n",
        "tensor = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
        "\n",
        "# Transpose the last two dimensions\n",
        "t_result = torch.t(tensor)\n",
        "t_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5u8ivXpVfD6",
        "outputId": "c98c9b31-8e15-4f4e-df55-bbf4a9547190"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4, 7],\n",
              "        [2, 5, 8],\n",
              "        [3, 6, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.permute\n",
        "* Description : The torch.permute method permutes the dimensions of a tensor"
      ],
      "metadata": {
        "id": "uPXzYupXWT-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a 3D tensor\n",
        "tensor = torch.randn(2,3,4)\n",
        "\n",
        "# Permute the dimensions\n",
        "permute_result = torch.permute(tensor,(2,0,1))\n",
        "permute_result.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7pa5X0-V99w",
        "outputId": "c287ca55-84eb-4ab1-a1c3-c0f960d7f2a8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.unsqueeze\n",
        "* Description : The torch.unsqueeze method returns a tensor with a dimension of size one inserted at the specified position"
      ],
      "metadata": {
        "id": "KOKAYpsUXD8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tensor\n",
        "tensor = torch.tensor([1,2,3,4])\n",
        "\n",
        "# Unsqueeze the tensor to add a new dimension\n",
        "unsqueeze_result = torch.unsqueeze(tensor, dim=0)\n",
        "unsqueeze_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkDgHLSMW1RZ",
        "outputId": "776b2bc4-dd06-462e-9e6f-5fd0b4a30fec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.squeeze\n",
        "* Description : The torch.sequeeze method returns a tensor with all the dimensions of size 1 removed"
      ],
      "metadata": {
        "id": "TcQ3WTMCXxHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tensor\n",
        "tensor = torch.tensor([[[1, 2, 3, 4]]])\n",
        "\n",
        "# Squeeze the tensor to remove dimensions of size 1\n",
        "squeeze_result = torch.squeeze(tensor)\n",
        "squeeze_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIVithrjXpEC",
        "outputId": "179c8c57-805d-4675-a013-fdd1ac7beb7a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.flatten\n",
        "* Description : The torch.flatten method flattens a tensor to a single dimension"
      ],
      "metadata": {
        "id": "Tp-uijZ6Yzy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a 2D tensor\n",
        "tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
        "\n",
        "# Flatten the tensor\n",
        "flatten_result = torch.flatten(tensor)\n",
        "flatten_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViGinwKQYcbQ",
        "outputId": "044eadc5-8558-4a3d-def7-4ba8ddb9f5fd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.norm\n",
        "* Description : The torch.norm method returns the norm of a tensor"
      ],
      "metadata": {
        "id": "dlwXMpIpZbvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tensor\n",
        "tensor = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
        "\n",
        "# Calculate the norm of the tensor\n",
        "norm_result = torch.norm(tensor)\n",
        "norm_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyetbgPmZXr4",
        "outputId": "ce93dd11-99fb-4a41-c7bf-6fa7f00dabb9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.4772)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.max\n",
        "* Description : The torch.max method returns the maximum value of all elements in a tensor"
      ],
      "metadata": {
        "id": "6fEROC3iaC4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tensor\n",
        "tensor = torch.tensor([[1,2],[3,4]])\n",
        "\n",
        "# Find the maximum value\n",
        "max_result = torch.max(tensor)\n",
        "max_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47pm5d9vZ5ri",
        "outputId": "7331f453-21d9-4ce7-ba5b-9d7b068e66fa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.min\n",
        "* Description : The torch.max method returns the minimum value of all elements in a tensor"
      ],
      "metadata": {
        "id": "MFlfhkiObJ_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tensor\n",
        "tensor = torch.tensor([[1,2],[3,4]])\n",
        "\n",
        "# Find the minimum value\n",
        "min_result = torch.min(tensor)\n",
        "min_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgyHQAsxalCo",
        "outputId": "92b88a2e-9ba5-4dc1-f4b5-a7f10d7aeaa7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.sum\n",
        "* Desctiprion : The torch.sum method returns sum of the all elements in a tensor"
      ],
      "metadata": {
        "id": "t8SB8SvJbd3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tensor\n",
        "tensor = torch.tensor([[1,2],[3,4]])\n",
        "\n",
        "# Find the sum of all elemants\n",
        "sum_result = torch.sum(tensor)\n",
        "sum_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLqhw7Kmbc5Y",
        "outputId": "cfb615a5-7ba3-42c4-a131-7a3cb62849ab"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.mean\n",
        "* Description : The torch.mean method returns the mean of all elements in a tensor"
      ],
      "metadata": {
        "id": "ePyV--Svb2TO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tensor\n",
        "tensor = torch.tensor([[1,2],[3,4]], dtype=torch.float32)\n",
        "\n",
        "# Find the mean of all elements\n",
        "mean_result = torch.mean(tensor)\n",
        "mean_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2QHFTsfbzo5",
        "outputId": "27804bf3-9ac8-4181-8b1c-188739311f8f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.5000)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.std\n",
        "* Description : The torch.std method returns the standard deviation of all elements in a tensor"
      ],
      "metadata": {
        "id": "FxXw6FTXcSSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tensor\n",
        "tensor = torch.tensor([[1,2],[3,4]], dtype=torch.float32)\n",
        "\n",
        "# Find the standard deviation of all elements\n",
        "std_result = torch.std(tensor)\n",
        "std_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBfunxxVcQSP",
        "outputId": "e9cfe774-bfd4-4c04-c5f4-f455e174aac1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.2910)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.var\n",
        "* Description : The torch.std method returns the variance of all elements in a tensor"
      ],
      "metadata": {
        "id": "hYRVzSD9coOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tensor\n",
        "tensor = torch.tensor([[1,2],[3,4]], dtype=torch.float32)\n",
        "\n",
        "# Find the variance of all elements\n",
        "var_result = torch.var(tensor)\n",
        "var_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4s8JnT3cm3n",
        "outputId": "889cca6a-27ce-44fa-a6e3-3d4c8d4b2ad2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.6667)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.argmax\n",
        "* Description : The torch.argmax method returns the indices of the maximum value of all elements along a specified axis"
      ],
      "metadata": {
        "id": "eW4OvjmGdToE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tensor\n",
        "tensor = torch.tensor([[1,2],[3,4]])\n",
        "\n",
        "# Find the index of the maximum value\n",
        "argmax_result = torch.argmax(tensor)\n",
        "argmax_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsbIU7Vjc93K",
        "outputId": "f16db04f-7f5e-4db5-f923-b9be93731af5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.argmin\n",
        "* Description : The torch.argmin method returns the indices of the maximum value of all elements along a specified axis"
      ],
      "metadata": {
        "id": "YywuLMGleqb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tensor\n",
        "tensor = torch.tensor([[1,2],[3,4]])\n",
        "\n",
        "# Find the index of the minimum value\n",
        "argmin_result = torch.argmin(tensor)\n",
        "argmin_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct5b7U1kdzbo",
        "outputId": "5165e0ea-87f3-4041-f105-f80963b9ee4d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn.Linear\n",
        "* Description : The torch.nn.Linear method creates a fully connected layer in a neural network"
      ],
      "metadata": {
        "id": "zWb8p9GafP-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "Z2BGNx3efK2v"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a fully connected layer\n",
        "linear = nn.Linear(in_features=2, out_features=3)\n",
        "\n",
        "# Define an input tensor\n",
        "input_tensor = torch.tensor([[1.0, 2.0]])\n",
        "\n",
        "# Pass the input tensor through the linear layer\n",
        "output_tensor = linear(input_tensor)\n",
        "output_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D6SAt8tf26-",
        "outputId": "a05c1ab2-2c0d-4549-9873-0ebffe7b970e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.2984,  0.3009,  1.5287]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn.Conv2d\n",
        "* Description : The torch.Conv.2d method creates a 2D convolutional layer in a neural network"
      ],
      "metadata": {
        "id": "0hxAEB6Wgvcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a 2D convolutional layer\n",
        "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\n",
        "\n",
        "# Define an input tensor\n",
        "input_tensor = torch.randn(1,1,5,5)\n",
        "\n",
        "# Pass the input tensor through the convolutional layer\n",
        "output_tensor = conv2d(input_tensor)\n",
        "output_tensor.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOWJsupegmqV",
        "outputId": "a8ab1194-0958-4d2e-f76f-f6c621fd208e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn.ReLU\n",
        "* Description : The torch.nn.ReLU method applies the ReLU activation function in a neural network"
      ],
      "metadata": {
        "id": "IcBW5v36hz32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a ReLU activation function\n",
        "relu = nn.ReLU()\n",
        "\n",
        "# Define an input tensor\n",
        "input_tensor = torch.tensor([-1.0, 0.0, 1.0])\n",
        "\n",
        "# Apply the ReLU activation function\n",
        "output_tensor = relu(input_tensor)\n",
        "output_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND0xo0wWhslN",
        "outputId": "871c7b60-071f-4830-8968-a5b905eca362"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn.Sigmoid\n",
        "* Description : The torch.nn.Sigmoid method applies the Sigmoid activation function in a neural network"
      ],
      "metadata": {
        "id": "KKRRGi1hissT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a ReLU activation function\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "# Define an input tensor\n",
        "input_tensor = torch.tensor([-1.0, 0.0, 1.0])\n",
        "\n",
        "# Apply the Sigmoid activation function\n",
        "output_tensor = sigmoid(input_tensor)\n",
        "output_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-I8MLJnioyR",
        "outputId": "e432c5d0-662a-4c99-bd45-ebce3a4c692a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2689, 0.5000, 0.7311])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn.CrossEntropyLoss\n",
        "* Description : The torch.nn.CrossEntropyLoss method creates a cross-entropy loss function for classification problem"
      ],
      "metadata": {
        "id": "13bvkilkjT0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Define a Cross-Entropy loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the inputs (logits) and target labels\n",
        "inputs = torch.tensor([[0.5, 1.5, 2.0]])\n",
        "targets = torch.tensor([2])\n",
        "\n",
        "# Compute the loss\n",
        "loss = loss_fn(inputs, targets)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZEBx4IqjSSC",
        "outputId": "96e97014-a475-416d-da27-cd4075930e5e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6041)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn.MSELoss\n",
        "* Description : The torch.nn.MSELoss method creates a mean squared error loss function for regression problems"
      ],
      "metadata": {
        "id": "ZJBi4pJGkoya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a mean squared error loss function\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Define the inputs and target labels\n",
        "inputs = torch.tensor([[0.5, 1.5, 2.0]])\n",
        "targets = torch.tensor([[1.0, 2.0, 3.0]])\n",
        "\n",
        "# Compute the loss\n",
        "loss = loss_fn(inputs, targets)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVcoCtFsknm6",
        "outputId": "890636db-2a51-452c-a04c-78d966aa311b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5000)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.optim.SGD\n",
        "* Description : The torch.optim.SGD method creates a stochastic gradient descent optimizer"
      ],
      "metadata": {
        "id": "YDaE_rqVlp-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "T1Mckh3BlgGk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple linear model\n",
        "model = nn.Linear(in_features=2, out_features=1)\n",
        "\n",
        "# Define a stochastic gradient descent optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Define a simple input tensor a target\n",
        "input_tensor = torch.tensor([[1.0, 2.0]])\n",
        "target = torch.tensor([[1.0]])\n",
        "\n",
        "# Forward Pass\n",
        "output = model(input_tensor)\n",
        "\n",
        "# Compute loss\n",
        "loss = nn.MSELoss()(output, target)\n",
        "\n",
        "# Backward pass and optimize\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pKNXYESmHL7",
        "outputId": "8b869382-3bb6-484f-ab44-480a13f9b447"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6708]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.optim.Adam\n",
        "* Description : The torch.optim.Adam method creates a Adam optimizer"
      ],
      "metadata": {
        "id": "y3iFT4xon8LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple linear model\n",
        "model = nn.Linear(in_features=2, out_features=1)\n",
        "\n",
        "# Define a stochastic gradient descent optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Define a simple input tensor a target\n",
        "input_tensor = torch.tensor([[1.0, 2.0]])\n",
        "target = torch.tensor([[1.0]])\n",
        "\n",
        "# Forward Pass\n",
        "output = model(input_tensor)\n",
        "\n",
        "# Compute loss\n",
        "loss = nn.MSELoss()(output, target)\n",
        "\n",
        "# Backward pass and optimize\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS4wqIkqnfLM",
        "outputId": "3cfb0c90-1710-4805-de36-bc63e1a4394d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1108]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.optim.lr_scheduler.StepLR\n",
        "* Description : The torch.optim.lr_scheduler.StepLR method creates a learning rate scheduler that decays the learning rate by a factor every few epochs"
      ],
      "metadata": {
        "id": "hggUwjkqohEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple linear model\n",
        "model = nn.Linear(in_features=2, out_features=1)\n",
        "\n",
        "# Define a stochastic gradient descent optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Define a learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "# Define a simple input tensor a target\n",
        "input_tensor = torch.tensor([[1.0, 2.0]])\n",
        "target = torch.tensor([[1.0]])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(20):\n",
        "\n",
        "  # Forward Pass\n",
        "  output = model(input_tensor)\n",
        "\n",
        "  # Compute loss\n",
        "  loss = nn.MSELoss()(output, target)\n",
        "\n",
        "  # Backward pass and optimize\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # Step the learning rate scheduler\n",
        "  scheduler.step()\n",
        "\n",
        "  print(f'Epoch {epoch+1}, Loss: {loss.item()}, LR: {scheduler.get_last_lr()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihJkXl4aocd0",
        "outputId": "040a9be4-2a70-4743-fa04-4242d804c10e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.3337379992008209, LR: [0.01]\n",
            "Epoch 2, Loss: 0.28912192583084106, LR: [0.01]\n",
            "Epoch 3, Loss: 0.24780584871768951, LR: [0.01]\n",
            "Epoch 4, Loss: 0.2098376601934433, LR: [0.01]\n",
            "Epoch 5, Loss: 0.17524853348731995, LR: [0.01]\n",
            "Epoch 6, Loss: 0.14405009150505066, LR: [0.01]\n",
            "Epoch 7, Loss: 0.11623126268386841, LR: [0.01]\n",
            "Epoch 8, Loss: 0.09175535291433334, LR: [0.01]\n",
            "Epoch 9, Loss: 0.07055686414241791, LR: [0.01]\n",
            "Epoch 10, Loss: 0.052538707852363586, LR: [0.001]\n",
            "Epoch 11, Loss: 0.03757016733288765, LR: [0.001]\n",
            "Epoch 12, Loss: 0.03625647351145744, LR: [0.001]\n",
            "Epoch 13, Loss: 0.035004377365112305, LR: [0.001]\n",
            "Epoch 14, Loss: 0.033806782215833664, LR: [0.001]\n",
            "Epoch 15, Loss: 0.03265800699591637, LR: [0.001]\n",
            "Epoch 16, Loss: 0.031553395092487335, LR: [0.001]\n",
            "Epoch 17, Loss: 0.03048911690711975, LR: [0.001]\n",
            "Epoch 18, Loss: 0.029461897909641266, LR: [0.001]\n",
            "Epoch 19, Loss: 0.028469055891036987, LR: [0.001]\n",
            "Epoch 20, Loss: 0.027508292347192764, LR: [0.0001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.autograd.grad\n",
        "* Description : The torch.autograd.grad method computes and returns the gradients of specified tensors"
      ],
      "metadata": {
        "id": "k23r5dakrgW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple function\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x ** 2\n",
        "\n",
        "# Compute gradients\n",
        "grad = torch.autograd.grad(outputs=y, inputs=x)\n",
        "grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxRUJioUrEvf",
        "outputId": "e3b462bc-d561-4182-f95e-e996bf76f8fc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(4.),)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.autograd.backward\n",
        "* Description : The torch.autograd.backward method computes the gradient of the current tensor w.r.t. graph leaves"
      ],
      "metadata": {
        "id": "gY05X8R3snEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple function\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x ** 2\n",
        "\n",
        "# Perform backpropagation\n",
        "y.backward()\n",
        "\n",
        "# Print the gradient\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xco3tNuAsRNx",
        "outputId": "97b5b039-e176-4658-8659-0a2dc5799ced"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.cuda.is_available\n",
        "* Description : The torch.cuda.is_available method returns a boolean indicating wheter CUDA is available for GPU acceleration"
      ],
      "metadata": {
        "id": "MYVG4ooWulde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available\n",
        "cuda_available = torch.cuda.is_available()\n",
        "print(cuda_available)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsmH0to0tdix",
        "outputId": "e80a071d-df4e-4537-d20e-afc86dee8f69"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.cuda.device\n",
        "* Description : The torch.cuda.device method is a context manager for selecting a CUDA device"
      ],
      "metadata": {
        "id": "mPOUA8Q5vUjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    with torch.cuda.device(0):\n",
        "        tensor = torch.tensor([1, 2, 3], device='cuda')\n",
        "        print(tensor)\n",
        "else:\n",
        "    print(\"GPU not available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfxNnLwXvR4m",
        "outputId": "23aa4c8e-b8d7-496f-8d59-1627cda7e965"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU not available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.save\n",
        "* Description : The torch.save method saves an object to a disk file"
      ],
      "metadata": {
        "id": "1cv0kUwWw1_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple tensor\n",
        "tensor = torch.tensor([1,2,3])\n",
        "\n",
        "# Save the tensor from a file\n",
        "torch.save(tensor, 'tensor.pth')"
      ],
      "metadata": {
        "id": "Scu48lE6vmwe"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.load\n",
        "* Description : The torch.load method loads an object saved with torch.save from a disk file"
      ],
      "metadata": {
        "id": "UfC1N1dJxkBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tensor from a file\n",
        "tensor = torch.load('tensor.pth')\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8yjYjVAxcnM",
        "outputId": "62d152e9-2c41-4fef-c2e6-d9d78259f784"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-c12e81608f9f>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tensor = torch.load('tensor.pth')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn.Module\n",
        "* Description : The torch.nn.Module method is the base class for all neural network modules"
      ],
      "metadata": {
        "id": "nsdTqzGlygXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple neural network\n",
        "class SimpleNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleNN, self).__init__()\n",
        "    self.fc1 = nn.Linear(2,2)\n",
        "    self.fc2 = nn.Linear(2,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = self.fc1(x)\n",
        "      x = torch.relu(x)\n",
        "      x = self.fc2(x)\n",
        "      return x\n",
        "\n",
        "# Instantiate the neural network\n",
        "model = SimpleNN()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkRMSMUdyENp",
        "outputId": "f518fa32-04ba-4489-9259-6cd785bc3168"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleNN(\n",
              "  (fc1): Linear(in_features=2, out_features=2, bias=True)\n",
              "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn.Sequential\n",
        "* Description : The torch.nn.Sequential method is a sequential container to stack multiple layers"
      ],
      "metadata": {
        "id": "oZe3_4HT0LRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple sequential model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2,2),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(2,1)\n",
        ")\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dniDpiLhzWyr",
        "outputId": "b362258b-8876-4b83-d627-a1c789734d8d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn.Dropout\n",
        "* Description : The torch.nn.Dropout method creates a dopout layer that randomly zeroes some of the elements of the input tensor with a probability"
      ],
      "metadata": {
        "id": "-YDaJtrM1BSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a dopout layer\n",
        "dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "# Define an input tensor\n",
        "input_tensor = torch.randn(2,3)\n",
        "\n",
        "# Apply dropout\n",
        "output_tensor = dropout(input_tensor)\n",
        "output_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPaDCAdi1Yr4",
        "outputId": "6560d333-6288-4f80-8852-9dd6cf0dc834"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0000, -0.0000,  3.0848],\n",
              "        [-0.7464,  0.8967, -0.9492]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn.BatchNorm2d\n",
        "* Description : The torch.nn.BatchNorm2d method creates a layer that normalizes the input for each mini-batch"
      ],
      "metadata": {
        "id": "ozl7vcdGhUYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a batch normalization layer\n",
        "batch_norm = nn.BatchNorm2d(num_features=3)\n",
        "\n",
        "# Define an input tensor\n",
        "input_tensor = torch.randn(2,3,4,5)\n",
        "\n",
        "# Apply batch normalization\n",
        "output_tensor = batch_norm(input_tensor)\n",
        "output_tensor"
      ],
      "metadata": {
        "id": "mKmcyRFZ1-lP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6423d530-ceba-4fc7-ac0b-4f059964de96"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.0055, -1.5178,  0.2924, -0.3165,  1.2437],\n",
              "          [-0.2288, -1.0512,  1.3020, -1.1500,  0.7707],\n",
              "          [ 0.9734,  0.1366, -1.2498,  0.9046,  0.1522],\n",
              "          [-0.7868,  0.4036, -2.0996,  0.5247, -1.4623]],\n",
              "\n",
              "         [[-0.1174,  1.1110,  0.3674,  1.0821, -0.9075],\n",
              "          [-0.7835,  1.0588, -1.9967, -0.9892,  1.5006],\n",
              "          [ 0.5812, -1.2506,  1.3620, -0.2887,  0.8735],\n",
              "          [-1.1874, -0.1137, -0.8554, -0.0490, -1.2590]],\n",
              "\n",
              "         [[-1.5438,  0.4388, -0.0853,  0.0653,  0.3369],\n",
              "          [ 0.1248,  1.1597,  2.4696,  0.2703,  0.1648],\n",
              "          [ 0.5243, -1.2261, -0.4959, -0.8976, -1.9304],\n",
              "          [-0.8943,  0.7186, -0.0715, -0.8624, -0.4985]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0281,  0.5425,  1.4867, -0.3844, -0.4928],\n",
              "          [-1.1424,  0.1128, -1.3787,  2.4512, -0.0623],\n",
              "          [ 0.8655,  0.6074, -0.8539, -1.6330,  1.1612],\n",
              "          [ 1.0674,  0.8229, -0.3970, -0.1278,  0.4910]],\n",
              "\n",
              "         [[-1.1861, -0.3424, -1.6311,  1.2168,  0.7684],\n",
              "          [ 0.1363, -0.2389, -0.6594,  1.3793,  0.0987],\n",
              "          [ 1.7895,  0.3198,  0.1864, -0.3267, -1.7590],\n",
              "          [ 0.8707,  1.2252,  0.2256,  0.8360, -1.0474]],\n",
              "\n",
              "         [[ 0.5342, -0.7640, -0.6927,  1.1056,  0.6213],\n",
              "          [-0.1477,  0.2086, -1.2769,  1.5221,  1.6644],\n",
              "          [-1.3949, -0.1923,  0.0034, -0.7794, -1.8885],\n",
              "          [ 0.8579,  0.7674, -0.3515,  0.6903,  1.7456]]]],\n",
              "       grad_fn=<NativeBatchNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.utils.data.DataLoader\n",
        "* Description : The torch.utils.data.DataLoader method creates a data loader to load datasets in batches"
      ],
      "metadata": {
        "id": "CS3i68x5kuPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define a simple dataset\n",
        "data = torch.randn(100, 2)\n",
        "targets = torch.randn(100, 1)\n",
        "dataset = TensorDataset(data, targets)\n",
        "\n",
        "# Create a data loader\n",
        "data_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "# Iterate trough the data loader\n",
        "for batch_data, batch_targets in data_loader:\n",
        "  print(batch_data.size(), batch_targets.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nz3Qj9EkbGH",
        "outputId": "0f680d6f-f07f-4b8c-b436-af1d46002438"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 2]) torch.Size([10, 1])\n",
            "torch.Size([10, 2]) torch.Size([10, 1])\n",
            "torch.Size([10, 2]) torch.Size([10, 1])\n",
            "torch.Size([10, 2]) torch.Size([10, 1])\n",
            "torch.Size([10, 2]) torch.Size([10, 1])\n",
            "torch.Size([10, 2]) torch.Size([10, 1])\n",
            "torch.Size([10, 2]) torch.Size([10, 1])\n",
            "torch.Size([10, 2]) torch.Size([10, 1])\n",
            "torch.Size([10, 2]) torch.Size([10, 1])\n",
            "torch.Size([10, 2]) torch.Size([10, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.utils.data.Dataset\n",
        "* Description : The torch.utils.data.Dataset method is an abstract class representing a dataset"
      ],
      "metadata": {
        "id": "ZmuhrvPmmQ4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Define a custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, data, targets):\n",
        "    self.data = data\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.data[index], self.tagets[index]\n",
        "\n",
        "# Create a dataset\n",
        "data = torch.randn(100, 2)\n",
        "targets = torch.randn(100, 1)\n",
        "dataset = TensorDataset(data, targets)\n",
        "\n",
        "# Get the length of the dataset\n",
        "print(len(dataset))\n",
        "\n",
        "# Get the first item from the dataset\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixR0RAQBmPk9",
        "outputId": "084e6ad7-3025-44e4-b83f-e4da7622fd72"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "(tensor([0.5393, 0.4414]), tensor([1.9416]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Linear Regression"
      ],
      "metadata": {
        "id": "U8N4mbvBnrAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "GRlOihnLnnd8"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset\n",
        "x_train = torch.tensor([[1.0],[2.0],[3.0],[4.0]])\n",
        "y_train = torch.tensor([[2.0],[4.0],[6.0],[8.0]])\n",
        "\n",
        "# Define a linear model\n",
        "model = nn.Linear(in_features=1, out_features=1)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "  # Forward pass\n",
        "  y_pred = model(x_train)\n",
        "\n",
        "  # Compute loss\n",
        "  loss = criterion(y_pred, y_train)\n",
        "\n",
        "  # Backward pass and optimize\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n",
        "\n",
        "# Print model parameters\n",
        "print(f'Weights: {model.weight.item()}, Bias: {model.bias.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eid9n1JkoAKk",
        "outputId": "0367a63c-184d-4233-a2fd-7f9640e8b996"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 26.034957885742188\n",
            "Epoch: 2, Loss: 18.070690155029297\n",
            "Epoch: 3, Loss: 12.544422149658203\n",
            "Epoch: 4, Loss: 8.709827423095703\n",
            "Epoch: 5, Loss: 6.049048900604248\n",
            "Epoch: 6, Loss: 4.202760696411133\n",
            "Epoch: 7, Loss: 2.921626091003418\n",
            "Epoch: 8, Loss: 2.0326414108276367\n",
            "Epoch: 9, Loss: 1.415762186050415\n",
            "Epoch: 10, Loss: 0.9876905679702759\n",
            "Epoch: 11, Loss: 0.6906288862228394\n",
            "Epoch: 12, Loss: 0.4844725728034973\n",
            "Epoch: 13, Loss: 0.3413935899734497\n",
            "Epoch: 14, Loss: 0.24208271503448486\n",
            "Epoch: 15, Loss: 0.17314209043979645\n",
            "Epoch: 16, Loss: 0.12527483701705933\n",
            "Epoch: 17, Loss: 0.09203003346920013\n",
            "Epoch: 18, Loss: 0.06893149018287659\n",
            "Epoch: 19, Loss: 0.0528736412525177\n",
            "Epoch: 20, Loss: 0.041701193898916245\n",
            "Epoch: 21, Loss: 0.03391900286078453\n",
            "Epoch: 22, Loss: 0.028489192947745323\n",
            "Epoch: 23, Loss: 0.024691997095942497\n",
            "Epoch: 24, Loss: 0.022027747705578804\n",
            "Epoch: 25, Loss: 0.020149869844317436\n",
            "Epoch: 26, Loss: 0.018817724660038948\n",
            "Epoch: 27, Loss: 0.01786450855433941\n",
            "Epoch: 28, Loss: 0.017174294218420982\n",
            "Epoch: 29, Loss: 0.01666683331131935\n",
            "Epoch: 30, Loss: 0.016286319121718407\n",
            "Epoch: 31, Loss: 0.015994010493159294\n",
            "Epoch: 32, Loss: 0.015763159841299057\n",
            "Epoch: 33, Loss: 0.015575092285871506\n",
            "Epoch: 34, Loss: 0.015416881069540977\n",
            "Epoch: 35, Loss: 0.015279502607882023\n",
            "Epoch: 36, Loss: 0.01515680830925703\n",
            "Epoch: 37, Loss: 0.015044467523694038\n",
            "Epoch: 38, Loss: 0.014939427375793457\n",
            "Epoch: 39, Loss: 0.01483962032943964\n",
            "Epoch: 40, Loss: 0.014743621461093426\n",
            "Epoch: 41, Loss: 0.01465042494237423\n",
            "Epoch: 42, Loss: 0.014559324830770493\n",
            "Epoch: 43, Loss: 0.014469851739704609\n",
            "Epoch: 44, Loss: 0.014381639659404755\n",
            "Epoch: 45, Loss: 0.014294521883130074\n",
            "Epoch: 46, Loss: 0.014208214357495308\n",
            "Epoch: 47, Loss: 0.014122748747467995\n",
            "Epoch: 48, Loss: 0.014037909917533398\n",
            "Epoch: 49, Loss: 0.013953689485788345\n",
            "Epoch: 50, Loss: 0.01387006975710392\n",
            "Epoch: 51, Loss: 0.013787025585770607\n",
            "Epoch: 52, Loss: 0.013704475946724415\n",
            "Epoch: 53, Loss: 0.013622533529996872\n",
            "Epoch: 54, Loss: 0.013541039079427719\n",
            "Epoch: 55, Loss: 0.013460038229823112\n",
            "Epoch: 56, Loss: 0.013379527255892754\n",
            "Epoch: 57, Loss: 0.013299519196152687\n",
            "Epoch: 58, Loss: 0.013219979591667652\n",
            "Epoch: 59, Loss: 0.013140974566340446\n",
            "Epoch: 60, Loss: 0.013062396086752415\n",
            "Epoch: 61, Loss: 0.01298428699374199\n",
            "Epoch: 62, Loss: 0.012906643562018871\n",
            "Epoch: 63, Loss: 0.012829471379518509\n",
            "Epoch: 64, Loss: 0.012752750888466835\n",
            "Epoch: 65, Loss: 0.012676529586315155\n",
            "Epoch: 66, Loss: 0.012600701302289963\n",
            "Epoch: 67, Loss: 0.012525362893939018\n",
            "Epoch: 68, Loss: 0.012450514361262321\n",
            "Epoch: 69, Loss: 0.012376047670841217\n",
            "Epoch: 70, Loss: 0.012302052229642868\n",
            "Epoch: 71, Loss: 0.012228523381054401\n",
            "Epoch: 72, Loss: 0.012155378237366676\n",
            "Epoch: 73, Loss: 0.012082749977707863\n",
            "Epoch: 74, Loss: 0.012010469101369381\n",
            "Epoch: 75, Loss: 0.011938653886318207\n",
            "Epoch: 76, Loss: 0.011867308057844639\n",
            "Epoch: 77, Loss: 0.011796364560723305\n",
            "Epoch: 78, Loss: 0.011725816875696182\n",
            "Epoch: 79, Loss: 0.011655712500214577\n",
            "Epoch: 80, Loss: 0.01158601138740778\n",
            "Epoch: 81, Loss: 0.011516734957695007\n",
            "Epoch: 82, Loss: 0.01144790556281805\n",
            "Epoch: 83, Loss: 0.011379465460777283\n",
            "Epoch: 84, Loss: 0.011311412788927555\n",
            "Epoch: 85, Loss: 0.011243775486946106\n",
            "Epoch: 86, Loss: 0.011176558211445808\n",
            "Epoch: 87, Loss: 0.011109746061265469\n",
            "Epoch: 88, Loss: 0.01104333158582449\n",
            "Epoch: 89, Loss: 0.010977296158671379\n",
            "Epoch: 90, Loss: 0.010911662131547928\n",
            "Epoch: 91, Loss: 0.010846404358744621\n",
            "Epoch: 92, Loss: 0.010781550779938698\n",
            "Epoch: 93, Loss: 0.010717112571001053\n",
            "Epoch: 94, Loss: 0.010653025470674038\n",
            "Epoch: 95, Loss: 0.010589320212602615\n",
            "Epoch: 96, Loss: 0.010525988414883614\n",
            "Epoch: 97, Loss: 0.010463109239935875\n",
            "Epoch: 98, Loss: 0.01040051132440567\n",
            "Epoch: 99, Loss: 0.010338352993130684\n",
            "Epoch: 100, Loss: 0.010276534594595432\n",
            "Weights: 2.0841164588928223, Bias: -0.24731296300888062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multilayer Perceptron for Classification"
      ],
      "metadata": {
        "id": "4XQoglZgqBLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "EgZS5zbcp5MW"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Define a multilayer perceptron model\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MLP, self).__init__()\n",
        "    self.fc1 = nn.Linear(20, 64)\n",
        "    self.fc2 = nn.Linear(64, 64)\n",
        "    self.fc3 = nn.Linear(64, 1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.fc1(x))\n",
        "    x = self.relu(self.fc2(x))\n",
        "    x = self.sigmoid(self.fc3(x))\n",
        "    return x\n",
        "\n",
        "# Instantiate the model, define loss and optimizer\n",
        "model = MLP()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "  # Forward pass\n",
        "  y_pred = model(X_train)\n",
        "\n",
        "  # Compute loss\n",
        "  loss = criterion(y_pred, y_train)\n",
        "\n",
        "  # Backward pass optimize\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n",
        "\n",
        "# Evaluate the model\n",
        "with torch.no_grad():\n",
        "  y_pred_test = model(X_test)\n",
        "  y_pred_label = y_pred_test.round()\n",
        "  accuracy = (y_pred_label.eq(y_test).sum() / y_test.shape[0]).item()\n",
        "  print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDidf8u-qgBG",
        "outputId": "ade7ffcc-1349-4693-c909-c746268be6ee"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.690386950969696\n",
            "Epoch: 2, Loss: 0.6851776242256165\n",
            "Epoch: 3, Loss: 0.6800220012664795\n",
            "Epoch: 4, Loss: 0.6748710870742798\n",
            "Epoch: 5, Loss: 0.6697039604187012\n",
            "Epoch: 6, Loss: 0.6644928455352783\n",
            "Epoch: 7, Loss: 0.6591967940330505\n",
            "Epoch: 8, Loss: 0.6537772417068481\n",
            "Epoch: 9, Loss: 0.6482372283935547\n",
            "Epoch: 10, Loss: 0.6425454020500183\n",
            "Epoch: 11, Loss: 0.6366557478904724\n",
            "Epoch: 12, Loss: 0.630556046962738\n",
            "Epoch: 13, Loss: 0.6242156028747559\n",
            "Epoch: 14, Loss: 0.6176191568374634\n",
            "Epoch: 15, Loss: 0.6107794046401978\n",
            "Epoch: 16, Loss: 0.6037126183509827\n",
            "Epoch: 17, Loss: 0.5963937640190125\n",
            "Epoch: 18, Loss: 0.5888208746910095\n",
            "Epoch: 19, Loss: 0.5809733271598816\n",
            "Epoch: 20, Loss: 0.572858989238739\n",
            "Epoch: 21, Loss: 0.5644861459732056\n",
            "Epoch: 22, Loss: 0.5558735132217407\n",
            "Epoch: 23, Loss: 0.5470138192176819\n",
            "Epoch: 24, Loss: 0.5379208326339722\n",
            "Epoch: 25, Loss: 0.528632402420044\n",
            "Epoch: 26, Loss: 0.519168496131897\n",
            "Epoch: 27, Loss: 0.5095350742340088\n",
            "Epoch: 28, Loss: 0.4997621178627014\n",
            "Epoch: 29, Loss: 0.4898925721645355\n",
            "Epoch: 30, Loss: 0.47995537519454956\n",
            "Epoch: 31, Loss: 0.469990611076355\n",
            "Epoch: 32, Loss: 0.46002644300460815\n",
            "Epoch: 33, Loss: 0.4501052796840668\n",
            "Epoch: 34, Loss: 0.4402613043785095\n",
            "Epoch: 35, Loss: 0.4305325746536255\n",
            "Epoch: 36, Loss: 0.4209679365158081\n",
            "Epoch: 37, Loss: 0.4116005301475525\n",
            "Epoch: 38, Loss: 0.402469277381897\n",
            "Epoch: 39, Loss: 0.3935922384262085\n",
            "Epoch: 40, Loss: 0.384990930557251\n",
            "Epoch: 41, Loss: 0.37670913338661194\n",
            "Epoch: 42, Loss: 0.3687465190887451\n",
            "Epoch: 43, Loss: 0.3611181676387787\n",
            "Epoch: 44, Loss: 0.3538551330566406\n",
            "Epoch: 45, Loss: 0.3469659090042114\n",
            "Epoch: 46, Loss: 0.34044498205184937\n",
            "Epoch: 47, Loss: 0.3342900574207306\n",
            "Epoch: 48, Loss: 0.32849541306495667\n",
            "Epoch: 49, Loss: 0.32305943965911865\n",
            "Epoch: 50, Loss: 0.3179807960987091\n",
            "Epoch: 51, Loss: 0.31323525309562683\n",
            "Epoch: 52, Loss: 0.30880916118621826\n",
            "Epoch: 53, Loss: 0.3046947121620178\n",
            "Epoch: 54, Loss: 0.30086764693260193\n",
            "Epoch: 55, Loss: 0.2973054051399231\n",
            "Epoch: 56, Loss: 0.2939823865890503\n",
            "Epoch: 57, Loss: 0.290881872177124\n",
            "Epoch: 58, Loss: 0.287978857755661\n",
            "Epoch: 59, Loss: 0.28524959087371826\n",
            "Epoch: 60, Loss: 0.2826720178127289\n",
            "Epoch: 61, Loss: 0.28023356199264526\n",
            "Epoch: 62, Loss: 0.27791520953178406\n",
            "Epoch: 63, Loss: 0.27570706605911255\n",
            "Epoch: 64, Loss: 0.2735857367515564\n",
            "Epoch: 65, Loss: 0.27154141664505005\n",
            "Epoch: 66, Loss: 0.2695605754852295\n",
            "Epoch: 67, Loss: 0.26763075590133667\n",
            "Epoch: 68, Loss: 0.2657315731048584\n",
            "Epoch: 69, Loss: 0.26386454701423645\n",
            "Epoch: 70, Loss: 0.26202166080474854\n",
            "Epoch: 71, Loss: 0.2601958215236664\n",
            "Epoch: 72, Loss: 0.25839003920555115\n",
            "Epoch: 73, Loss: 0.2565942704677582\n",
            "Epoch: 74, Loss: 0.2548108994960785\n",
            "Epoch: 75, Loss: 0.25303393602371216\n",
            "Epoch: 76, Loss: 0.25126883387565613\n",
            "Epoch: 77, Loss: 0.24950458109378815\n",
            "Epoch: 78, Loss: 0.24775180220603943\n",
            "Epoch: 79, Loss: 0.2460194081068039\n",
            "Epoch: 80, Loss: 0.24429000914096832\n",
            "Epoch: 81, Loss: 0.2425641268491745\n",
            "Epoch: 82, Loss: 0.24084533751010895\n",
            "Epoch: 83, Loss: 0.2391366958618164\n",
            "Epoch: 84, Loss: 0.23745185136795044\n",
            "Epoch: 85, Loss: 0.2357698231935501\n",
            "Epoch: 86, Loss: 0.2340952754020691\n",
            "Epoch: 87, Loss: 0.23243431746959686\n",
            "Epoch: 88, Loss: 0.2307923436164856\n",
            "Epoch: 89, Loss: 0.2291637659072876\n",
            "Epoch: 90, Loss: 0.22754980623722076\n",
            "Epoch: 91, Loss: 0.22595752775669098\n",
            "Epoch: 92, Loss: 0.22437304258346558\n",
            "Epoch: 93, Loss: 0.2228001058101654\n",
            "Epoch: 94, Loss: 0.22123457491397858\n",
            "Epoch: 95, Loss: 0.21967846155166626\n",
            "Epoch: 96, Loss: 0.21813152730464935\n",
            "Epoch: 97, Loss: 0.21659335494041443\n",
            "Epoch: 98, Loss: 0.21505214273929596\n",
            "Epoch: 99, Loss: 0.21352045238018036\n",
            "Epoch: 100, Loss: 0.2120039016008377\n",
            "Test Accuracy: 83.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network for Image Classification"
      ],
      "metadata": {
        "id": "JMLwQs0FvXWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "kC7mpHnXudCf"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Simple CNN Model\n",
        "class SimpleCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleCNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "    self.fc1 = nn.Linear(64*7*7, 128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.conv1(x))\n",
        "    x = self.maxpool(x)\n",
        "    x = self.relu(self.conv2(x))\n",
        "    x = self.maxpool(x)\n",
        "    x = x.view(-1, 64*7*7)\n",
        "    x = self.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "# Prepare the dataset and data loader\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = torchvision.datasets.MNIST(root= './data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Instantiate the model, define loss and optimizer\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(5):\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    # Forward pass\n",
        "    output = model(data)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    # Backward pass optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch_idx % 100 == 0:\n",
        "      print(f'Epoch: {epoch+1}, Batch: {batch_idx+1}, Loss: {loss.item()}')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmcXvpmsvzN3",
        "outputId": "5552889b-01e9-4a84-aa4a-3f6ed8a96e5c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 9.91M/9.91M [00:00<00:00, 14.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 28.9k/28.9k [00:00<00:00, 460kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1.65M/1.65M [00:00<00:00, 4.02MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 4.54k/4.54k [00:00<00:00, 6.80MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch: 1, Batch: 1, Loss: 2.3187248706817627\n",
            "Epoch: 1, Batch: 101, Loss: 0.5618106126785278\n",
            "Epoch: 1, Batch: 201, Loss: 0.3069362938404083\n",
            "Epoch: 1, Batch: 301, Loss: 0.29801273345947266\n",
            "Epoch: 1, Batch: 401, Loss: 0.15818212926387787\n",
            "Epoch: 1, Batch: 501, Loss: 0.3519284129142761\n",
            "Epoch: 1, Batch: 601, Loss: 0.17800453305244446\n",
            "Epoch: 1, Batch: 701, Loss: 0.08538595587015152\n",
            "Epoch: 1, Batch: 801, Loss: 0.044815268367528915\n",
            "Epoch: 1, Batch: 901, Loss: 0.03169817849993706\n",
            "Epoch: 2, Batch: 1, Loss: 0.12648239731788635\n",
            "Epoch: 2, Batch: 101, Loss: 0.04987381771206856\n",
            "Epoch: 2, Batch: 201, Loss: 0.11632554978132248\n",
            "Epoch: 2, Batch: 301, Loss: 0.33757394552230835\n",
            "Epoch: 2, Batch: 401, Loss: 0.1065731942653656\n",
            "Epoch: 2, Batch: 501, Loss: 0.17835113406181335\n",
            "Epoch: 2, Batch: 601, Loss: 0.10117293149232864\n",
            "Epoch: 2, Batch: 701, Loss: 0.020709656178951263\n",
            "Epoch: 2, Batch: 801, Loss: 0.03745884448289871\n",
            "Epoch: 2, Batch: 901, Loss: 0.007919251918792725\n",
            "Epoch: 3, Batch: 1, Loss: 0.1456586867570877\n",
            "Epoch: 3, Batch: 101, Loss: 0.044433120638132095\n",
            "Epoch: 3, Batch: 201, Loss: 0.06594191491603851\n",
            "Epoch: 3, Batch: 301, Loss: 0.08445549011230469\n",
            "Epoch: 3, Batch: 401, Loss: 0.09522987902164459\n",
            "Epoch: 3, Batch: 501, Loss: 0.09046655893325806\n",
            "Epoch: 3, Batch: 601, Loss: 0.06778226792812347\n",
            "Epoch: 3, Batch: 701, Loss: 0.11243095248937607\n",
            "Epoch: 3, Batch: 801, Loss: 0.042447514832019806\n",
            "Epoch: 3, Batch: 901, Loss: 0.07319434732198715\n",
            "Epoch: 4, Batch: 1, Loss: 0.10631071031093597\n",
            "Epoch: 4, Batch: 101, Loss: 0.04369958117604256\n",
            "Epoch: 4, Batch: 201, Loss: 0.07887407392263412\n",
            "Epoch: 4, Batch: 301, Loss: 0.03688696026802063\n",
            "Epoch: 4, Batch: 401, Loss: 0.1797005534172058\n",
            "Epoch: 4, Batch: 501, Loss: 0.010676154866814613\n",
            "Epoch: 4, Batch: 601, Loss: 0.014790540561079979\n",
            "Epoch: 4, Batch: 701, Loss: 0.07339774072170258\n",
            "Epoch: 4, Batch: 801, Loss: 0.08191709965467453\n",
            "Epoch: 4, Batch: 901, Loss: 0.04894602298736572\n",
            "Epoch: 5, Batch: 1, Loss: 0.1310136765241623\n",
            "Epoch: 5, Batch: 101, Loss: 0.02945636212825775\n",
            "Epoch: 5, Batch: 201, Loss: 0.0041526565328240395\n",
            "Epoch: 5, Batch: 301, Loss: 0.004013580735772848\n",
            "Epoch: 5, Batch: 401, Loss: 0.01860608346760273\n",
            "Epoch: 5, Batch: 501, Loss: 0.018272103741765022\n",
            "Epoch: 5, Batch: 601, Loss: 0.09131807833909988\n",
            "Epoch: 5, Batch: 701, Loss: 0.08020856231451035\n",
            "Epoch: 5, Batch: 801, Loss: 0.0971735492348671\n",
            "Epoch: 5, Batch: 901, Loss: 0.012997039593756199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with Pretrained Models"
      ],
      "metadata": {
        "id": "gNEnN3Xd0ZI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "7j2PaKRIz0Qr"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pretrained ResNet18 model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the final layer\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# Replace the final layer with a new fully connected layer\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "\n",
        "# Prepare the dataset and data loader\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = torchvision.datasets.CIFAR10(root= './data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(5):\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    # Forward pass\n",
        "    output = model(data)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    # Backward pass optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch_idx % 100 == 0:\n",
        "      print(f'Epoch: {epoch+1}, Batch: {batch_idx+1}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8_aWC_30qJI",
        "outputId": "5e8775b1-da86-4732-b2ba-dcb0957f5411"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|| 44.7M/44.7M [00:00<00:00, 89.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 170M/170M [00:04<00:00, 41.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Epoch: 1, Batch: 1, Loss: 2.7112956047058105\n",
            "Epoch: 1, Batch: 101, Loss: 1.8503146171569824\n",
            "Epoch: 1, Batch: 201, Loss: 1.8362411260604858\n",
            "Epoch: 1, Batch: 301, Loss: 1.6188535690307617\n",
            "Epoch: 1, Batch: 401, Loss: 1.3484179973602295\n",
            "Epoch: 1, Batch: 501, Loss: 1.5967048406600952\n",
            "Epoch: 1, Batch: 601, Loss: 1.8243507146835327\n",
            "Epoch: 1, Batch: 701, Loss: 1.3269680738449097\n",
            "Epoch: 2, Batch: 1, Loss: 1.8344467878341675\n",
            "Epoch: 2, Batch: 101, Loss: 1.6329410076141357\n",
            "Epoch: 2, Batch: 201, Loss: 1.623386263847351\n",
            "Epoch: 2, Batch: 301, Loss: 1.618338942527771\n",
            "Epoch: 2, Batch: 401, Loss: 1.7516114711761475\n",
            "Epoch: 2, Batch: 501, Loss: 1.551397681236267\n",
            "Epoch: 2, Batch: 601, Loss: 1.6924344301223755\n",
            "Epoch: 2, Batch: 701, Loss: 1.576602578163147\n",
            "Epoch: 3, Batch: 1, Loss: 1.3825010061264038\n",
            "Epoch: 3, Batch: 101, Loss: 1.279874324798584\n",
            "Epoch: 3, Batch: 201, Loss: 1.4278780221939087\n",
            "Epoch: 3, Batch: 301, Loss: 1.4697835445404053\n",
            "Epoch: 3, Batch: 401, Loss: 1.6556553840637207\n",
            "Epoch: 3, Batch: 501, Loss: 1.7717269659042358\n",
            "Epoch: 3, Batch: 601, Loss: 1.4966239929199219\n",
            "Epoch: 3, Batch: 701, Loss: 1.4434465169906616\n",
            "Epoch: 4, Batch: 1, Loss: 2.0534090995788574\n",
            "Epoch: 4, Batch: 101, Loss: 1.7042548656463623\n",
            "Epoch: 4, Batch: 201, Loss: 1.5930511951446533\n",
            "Epoch: 4, Batch: 301, Loss: 1.754211664199829\n",
            "Epoch: 4, Batch: 401, Loss: 1.4350754022598267\n",
            "Epoch: 4, Batch: 501, Loss: 1.4136874675750732\n",
            "Epoch: 4, Batch: 601, Loss: 1.4787418842315674\n",
            "Epoch: 4, Batch: 701, Loss: 1.5338053703308105\n",
            "Epoch: 5, Batch: 1, Loss: 1.5096545219421387\n",
            "Epoch: 5, Batch: 101, Loss: 1.62884521484375\n",
            "Epoch: 5, Batch: 201, Loss: 1.5026346445083618\n",
            "Epoch: 5, Batch: 301, Loss: 1.7445011138916016\n",
            "Epoch: 5, Batch: 401, Loss: 1.6262677907943726\n",
            "Epoch: 5, Batch: 501, Loss: 1.6023330688476562\n",
            "Epoch: 5, Batch: 601, Loss: 1.3548301458358765\n",
            "Epoch: 5, Batch: 701, Loss: 1.6682568788528442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Network for Sequence Modeling"
      ],
      "metadata": {
        "id": "cFOx0yyM2gQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "jNI-52Ne2Z6w"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Simple RNN Model\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Create some dummy data\n",
        "x_train = torch.randn(100, 10, 1)  # 100 sequences of length 10\n",
        "y_train = torch.randn(100, 1)      # 100 target values\n",
        "\n",
        "# Instantiate the model, define loss and optimizer\n",
        "model = SimpleRNN(input_size=1, hidden_size=20, output_size=1)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    # Forward pass\n",
        "    y_pred = model(x_train)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIxnAC1K2uyP",
        "outputId": "928522ba-b8b3-4a79-bdb7-f2e2fb1df5b3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.9574964642524719\n",
            "Epoch: 2, Loss: 0.9206814765930176\n",
            "Epoch: 3, Loss: 0.9063995480537415\n",
            "Epoch: 4, Loss: 0.9062814116477966\n",
            "Epoch: 5, Loss: 0.9085456728935242\n",
            "Epoch: 6, Loss: 0.9051200747489929\n",
            "Epoch: 7, Loss: 0.8992499709129333\n",
            "Epoch: 8, Loss: 0.8952388763427734\n",
            "Epoch: 9, Loss: 0.8946941494941711\n",
            "Epoch: 10, Loss: 0.8961865305900574\n",
            "Epoch: 11, Loss: 0.896555483341217\n",
            "Epoch: 12, Loss: 0.8951873183250427\n",
            "Epoch: 13, Loss: 0.893237292766571\n",
            "Epoch: 14, Loss: 0.8912220597267151\n",
            "Epoch: 15, Loss: 0.8892372250556946\n",
            "Epoch: 16, Loss: 0.8875116109848022\n",
            "Epoch: 17, Loss: 0.8861852288246155\n",
            "Epoch: 18, Loss: 0.8848648071289062\n",
            "Epoch: 19, Loss: 0.8828138113021851\n",
            "Epoch: 20, Loss: 0.8799920678138733\n",
            "Epoch: 21, Loss: 0.8768643140792847\n",
            "Epoch: 22, Loss: 0.8732627034187317\n",
            "Epoch: 23, Loss: 0.8684607148170471\n",
            "Epoch: 24, Loss: 0.8621922135353088\n",
            "Epoch: 25, Loss: 0.8546848893165588\n",
            "Epoch: 26, Loss: 0.8454296588897705\n",
            "Epoch: 27, Loss: 0.8377335071563721\n",
            "Epoch: 28, Loss: 0.8312197923660278\n",
            "Epoch: 29, Loss: 0.8199487328529358\n",
            "Epoch: 30, Loss: 0.8067520260810852\n",
            "Epoch: 31, Loss: 0.7940431833267212\n",
            "Epoch: 32, Loss: 0.7772541046142578\n",
            "Epoch: 33, Loss: 0.7536820769309998\n",
            "Epoch: 34, Loss: 0.7339919805526733\n",
            "Epoch: 35, Loss: 0.7458721995353699\n",
            "Epoch: 36, Loss: 0.7990092635154724\n",
            "Epoch: 37, Loss: 0.6920500993728638\n",
            "Epoch: 38, Loss: 0.756493330001831\n",
            "Epoch: 39, Loss: 0.6946907043457031\n",
            "Epoch: 40, Loss: 0.6862335801124573\n",
            "Epoch: 41, Loss: 0.7030759453773499\n",
            "Epoch: 42, Loss: 0.6760259866714478\n",
            "Epoch: 43, Loss: 0.6635900139808655\n",
            "Epoch: 44, Loss: 0.6667881608009338\n",
            "Epoch: 45, Loss: 0.6460248827934265\n",
            "Epoch: 46, Loss: 0.6226970553398132\n",
            "Epoch: 47, Loss: 0.6158490777015686\n",
            "Epoch: 48, Loss: 0.5875343084335327\n",
            "Epoch: 49, Loss: 0.5714368224143982\n",
            "Epoch: 50, Loss: 0.5646290183067322\n",
            "Epoch: 51, Loss: 0.5402631759643555\n",
            "Epoch: 52, Loss: 0.5346060395240784\n",
            "Epoch: 53, Loss: 0.5192440748214722\n",
            "Epoch: 54, Loss: 0.4953923523426056\n",
            "Epoch: 55, Loss: 0.4846583902835846\n",
            "Epoch: 56, Loss: 0.46532806754112244\n",
            "Epoch: 57, Loss: 0.4548209309577942\n",
            "Epoch: 58, Loss: 0.43497559428215027\n",
            "Epoch: 59, Loss: 0.42600440979003906\n",
            "Epoch: 60, Loss: 0.41064244508743286\n",
            "Epoch: 61, Loss: 0.39509761333465576\n",
            "Epoch: 62, Loss: 0.3859729766845703\n",
            "Epoch: 63, Loss: 0.36839091777801514\n",
            "Epoch: 64, Loss: 0.35312485694885254\n",
            "Epoch: 65, Loss: 0.3436864912509918\n",
            "Epoch: 66, Loss: 0.336469829082489\n",
            "Epoch: 67, Loss: 0.3243590295314789\n",
            "Epoch: 68, Loss: 0.31185153126716614\n",
            "Epoch: 69, Loss: 0.3014813959598541\n",
            "Epoch: 70, Loss: 0.2925611436367035\n",
            "Epoch: 71, Loss: 0.2887444794178009\n",
            "Epoch: 72, Loss: 0.28769341111183167\n",
            "Epoch: 73, Loss: 0.29554930329322815\n",
            "Epoch: 74, Loss: 0.3123314082622528\n",
            "Epoch: 75, Loss: 0.2571761906147003\n",
            "Epoch: 76, Loss: 0.23732654750347137\n",
            "Epoch: 77, Loss: 0.25163087248802185\n",
            "Epoch: 78, Loss: 0.21142001450061798\n",
            "Epoch: 79, Loss: 0.22625397145748138\n",
            "Epoch: 80, Loss: 0.20744965970516205\n",
            "Epoch: 81, Loss: 0.19492481648921967\n",
            "Epoch: 82, Loss: 0.19916760921478271\n",
            "Epoch: 83, Loss: 0.172530859708786\n",
            "Epoch: 84, Loss: 0.18073417246341705\n",
            "Epoch: 85, Loss: 0.16195908188819885\n",
            "Epoch: 86, Loss: 0.1631147414445877\n",
            "Epoch: 87, Loss: 0.15589691698551178\n",
            "Epoch: 88, Loss: 0.14565180242061615\n",
            "Epoch: 89, Loss: 0.14950168132781982\n",
            "Epoch: 90, Loss: 0.13416628539562225\n",
            "Epoch: 91, Loss: 0.13409043848514557\n",
            "Epoch: 92, Loss: 0.12774881720542908\n",
            "Epoch: 93, Loss: 0.11973871290683746\n",
            "Epoch: 94, Loss: 0.12018217891454697\n",
            "Epoch: 95, Loss: 0.11051414161920547\n",
            "Epoch: 96, Loss: 0.11057014763355255\n",
            "Epoch: 97, Loss: 0.10527565330266953\n",
            "Epoch: 98, Loss: 0.0997755154967308\n",
            "Epoch: 99, Loss: 0.09974592179059982\n",
            "Epoch: 100, Loss: 0.09260420501232147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoEncoder for Dimensionality Reduction"
      ],
      "metadata": {
        "id": "z36q3iZ25Hrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "7jj5ICp05HWU"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Simple AutoEncoder Model\n",
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Linear(784, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 12),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(12, 3)\n",
        "    )\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(3, 12),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(12, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 784),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.decoder(x)\n",
        "    return x\n",
        "\n",
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root= './data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Instantiate the model, define loss and optimizer\n",
        "model = Autoencoder()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(5):\n",
        "  for batch_idx, (data, _) in enumerate(train_loader):\n",
        "    # Flatten the data\n",
        "    data = data.view(-1, 784)\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(data)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(output, data)\n",
        "\n",
        "    # Backward pass optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch_idx % 100 == 0:\n",
        "      print(f'Epoch: {epoch+1}, Batch: {batch_idx+1}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofjRWmj95biW",
        "outputId": "54ca05a1-177b-4f01-99b7-52c33175d1ed"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Batch: 1, Loss: 1.9401276111602783\n",
            "Epoch: 1, Batch: 101, Loss: 0.9247053265571594\n",
            "Epoch: 1, Batch: 201, Loss: 0.924060583114624\n",
            "Epoch: 1, Batch: 301, Loss: 0.926344633102417\n",
            "Epoch: 1, Batch: 401, Loss: 0.9255186319351196\n",
            "Epoch: 1, Batch: 501, Loss: 0.9242287278175354\n",
            "Epoch: 1, Batch: 601, Loss: 0.9252778887748718\n",
            "Epoch: 1, Batch: 701, Loss: 0.9248301982879639\n",
            "Epoch: 1, Batch: 801, Loss: 0.9234321713447571\n",
            "Epoch: 1, Batch: 901, Loss: 0.9239531755447388\n",
            "Epoch: 2, Batch: 1, Loss: 0.9264110922813416\n",
            "Epoch: 2, Batch: 101, Loss: 0.9275420904159546\n",
            "Epoch: 2, Batch: 201, Loss: 0.9251922369003296\n",
            "Epoch: 2, Batch: 301, Loss: 0.9264194965362549\n",
            "Epoch: 2, Batch: 401, Loss: 0.9246658086776733\n",
            "Epoch: 2, Batch: 501, Loss: 0.9301068186759949\n",
            "Epoch: 2, Batch: 601, Loss: 0.9240251779556274\n",
            "Epoch: 2, Batch: 701, Loss: 0.9240109920501709\n",
            "Epoch: 2, Batch: 801, Loss: 0.9282069206237793\n",
            "Epoch: 2, Batch: 901, Loss: 0.9280322194099426\n",
            "Epoch: 3, Batch: 1, Loss: 0.9243888258934021\n",
            "Epoch: 3, Batch: 101, Loss: 0.9255900382995605\n",
            "Epoch: 3, Batch: 201, Loss: 0.9260638356208801\n",
            "Epoch: 3, Batch: 301, Loss: 0.9286913275718689\n",
            "Epoch: 3, Batch: 401, Loss: 0.9233068227767944\n",
            "Epoch: 3, Batch: 501, Loss: 0.9264716506004333\n",
            "Epoch: 3, Batch: 601, Loss: 0.9224538207054138\n",
            "Epoch: 3, Batch: 701, Loss: 0.9245964288711548\n",
            "Epoch: 3, Batch: 801, Loss: 0.9275797605514526\n",
            "Epoch: 3, Batch: 901, Loss: 0.9234429001808167\n",
            "Epoch: 4, Batch: 1, Loss: 0.9228649735450745\n",
            "Epoch: 4, Batch: 101, Loss: 0.9233512282371521\n",
            "Epoch: 4, Batch: 201, Loss: 0.9265586733818054\n",
            "Epoch: 4, Batch: 301, Loss: 0.9231562614440918\n",
            "Epoch: 4, Batch: 401, Loss: 0.9286565780639648\n",
            "Epoch: 4, Batch: 501, Loss: 0.9295399188995361\n",
            "Epoch: 4, Batch: 601, Loss: 0.9203473329544067\n",
            "Epoch: 4, Batch: 701, Loss: 0.9280349612236023\n",
            "Epoch: 4, Batch: 801, Loss: 0.9274338483810425\n",
            "Epoch: 4, Batch: 901, Loss: 0.9303112626075745\n",
            "Epoch: 5, Batch: 1, Loss: 0.9268417358398438\n",
            "Epoch: 5, Batch: 101, Loss: 0.9258567094802856\n",
            "Epoch: 5, Batch: 201, Loss: 0.9250485897064209\n",
            "Epoch: 5, Batch: 301, Loss: 0.9260483384132385\n",
            "Epoch: 5, Batch: 401, Loss: 0.9234572649002075\n",
            "Epoch: 5, Batch: 501, Loss: 0.9293116927146912\n",
            "Epoch: 5, Batch: 601, Loss: 0.9223203659057617\n",
            "Epoch: 5, Batch: 701, Loss: 0.9247777462005615\n",
            "Epoch: 5, Batch: 801, Loss: 0.9210398197174072\n",
            "Epoch: 5, Batch: 901, Loss: 0.9213182926177979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Network (GAN) for Image Generation"
      ],
      "metadata": {
        "id": "S4SmIPNIAyhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "PWEUenca71fD"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the generator model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 784),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Define the discriminator model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(784, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Hyperparameters\n",
        "z_dim = 64\n",
        "batch_size = 64\n",
        "lr = 0.0002\n",
        "\n",
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Instantiate the models and optimizers\n",
        "generator = Generator(z_dim)\n",
        "discriminator = Discriminator()\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=lr)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(5):\n",
        "    for batch_idx, (real_images, _) in enumerate(train_loader):\n",
        "        # Train the discriminator\n",
        "        real_images = real_images.view(-1, 784)\n",
        "        real_labels = torch.ones(real_images.size(0), 1)\n",
        "        fake_labels = torch.zeros(real_images.size(0), 1)\n",
        "\n",
        "        d_optimizer.zero_grad()\n",
        "        outputs = discriminator(real_images)\n",
        "        real_loss = criterion(outputs, real_labels)\n",
        "        real_loss.backward()\n",
        "\n",
        "        z = torch.randn(real_images.size(0), z_dim)\n",
        "        fake_images = generator(z)\n",
        "        outputs = discriminator(fake_images.detach())\n",
        "        fake_loss = criterion(outputs, fake_labels)\n",
        "        fake_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # Train the generator\n",
        "        g_optimizer.zero_grad()\n",
        "        z = torch.randn(real_images.size(0), z_dim)\n",
        "        fake_images = generator(z)\n",
        "        outputs = discriminator(fake_images)\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        # Print the progress\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Epoch: {epoch+1}, Batch: {batch_idx+1}, D_Loss: {real_loss.item() + fake_loss.item()}, G_Loss: {g_loss.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BSo5OPuBPiM",
        "outputId": "1115b7eb-cd25-4723-b9b9-1dab3a9d44f7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Batch: 1, D_Loss: 1.3698039054870605, G_Loss: 0.7255949378013611\n",
            "Epoch: 1, Batch: 101, D_Loss: 0.6966733266599476, G_Loss: 1.315826654434204\n",
            "Epoch: 1, Batch: 201, D_Loss: 0.05847282148897648, G_Loss: 4.69512939453125\n",
            "Epoch: 1, Batch: 301, D_Loss: 2.2643869519233704, G_Loss: 6.669920444488525\n",
            "Epoch: 1, Batch: 401, D_Loss: 0.10655095428228378, G_Loss: 8.54127025604248\n",
            "Epoch: 1, Batch: 501, D_Loss: 0.4716063588857651, G_Loss: 9.711624145507812\n",
            "Epoch: 1, Batch: 601, D_Loss: 0.008309667930006981, G_Loss: 8.433843612670898\n",
            "Epoch: 1, Batch: 701, D_Loss: 0.19639632292091846, G_Loss: 6.885838508605957\n",
            "Epoch: 1, Batch: 801, D_Loss: 0.9398174285888672, G_Loss: 5.788382053375244\n",
            "Epoch: 1, Batch: 901, D_Loss: 0.014115361496806145, G_Loss: 12.57106876373291\n",
            "Epoch: 2, Batch: 1, D_Loss: 0.03086218192765955, G_Loss: 9.052335739135742\n",
            "Epoch: 2, Batch: 101, D_Loss: 0.012346431380137801, G_Loss: 5.5352559089660645\n",
            "Epoch: 2, Batch: 201, D_Loss: 0.01337520481320098, G_Loss: 9.844219207763672\n",
            "Epoch: 2, Batch: 301, D_Loss: 0.06939797522500157, G_Loss: 7.1926116943359375\n",
            "Epoch: 2, Batch: 401, D_Loss: 0.0014299122558441013, G_Loss: 9.423293113708496\n",
            "Epoch: 2, Batch: 501, D_Loss: 0.05614374077413231, G_Loss: 8.763848304748535\n",
            "Epoch: 2, Batch: 601, D_Loss: 0.024517562240362167, G_Loss: 26.17257308959961\n",
            "Epoch: 2, Batch: 701, D_Loss: 0.02803826332092285, G_Loss: 10.439509391784668\n",
            "Epoch: 2, Batch: 801, D_Loss: 1.2055062055587769, G_Loss: 9.926011085510254\n",
            "Epoch: 2, Batch: 901, D_Loss: 1.0644516795873642, G_Loss: 4.574772357940674\n",
            "Epoch: 3, Batch: 1, D_Loss: 0.13351404294371605, G_Loss: 8.849549293518066\n",
            "Epoch: 3, Batch: 101, D_Loss: 0.6412773877382278, G_Loss: 7.571604251861572\n",
            "Epoch: 3, Batch: 201, D_Loss: 0.7730520069599152, G_Loss: 2.827026844024658\n",
            "Epoch: 3, Batch: 301, D_Loss: 0.46733617782592773, G_Loss: 3.7784838676452637\n",
            "Epoch: 3, Batch: 401, D_Loss: 0.8575232177972794, G_Loss: 1.460587978363037\n",
            "Epoch: 3, Batch: 501, D_Loss: 0.8449006676673889, G_Loss: 1.2941341400146484\n",
            "Epoch: 3, Batch: 601, D_Loss: 0.7728091180324554, G_Loss: 1.2193171977996826\n",
            "Epoch: 3, Batch: 701, D_Loss: 1.1280580759048462, G_Loss: 2.5354726314544678\n",
            "Epoch: 3, Batch: 801, D_Loss: 1.0638073682785034, G_Loss: 4.335022926330566\n",
            "Epoch: 3, Batch: 901, D_Loss: 0.24420949630439281, G_Loss: 4.39931583404541\n",
            "Epoch: 4, Batch: 1, D_Loss: 0.928472101688385, G_Loss: 2.670477867126465\n",
            "Epoch: 4, Batch: 101, D_Loss: 1.081569492816925, G_Loss: 1.8776812553405762\n",
            "Epoch: 4, Batch: 201, D_Loss: 0.06460812874138355, G_Loss: 8.741137504577637\n",
            "Epoch: 4, Batch: 301, D_Loss: 0.15121666342020035, G_Loss: 3.9443442821502686\n",
            "Epoch: 4, Batch: 401, D_Loss: 0.07229611650109291, G_Loss: 4.391979694366455\n",
            "Epoch: 4, Batch: 501, D_Loss: 0.09746953099966049, G_Loss: 3.8493149280548096\n",
            "Epoch: 4, Batch: 601, D_Loss: 0.03927611745893955, G_Loss: 4.4856743812561035\n",
            "Epoch: 4, Batch: 701, D_Loss: 0.1581510826945305, G_Loss: 6.0951151847839355\n",
            "Epoch: 4, Batch: 801, D_Loss: 0.29567290283739567, G_Loss: 5.135092735290527\n",
            "Epoch: 4, Batch: 901, D_Loss: 0.28736934065818787, G_Loss: 6.941054821014404\n",
            "Epoch: 5, Batch: 1, D_Loss: 0.29839256405830383, G_Loss: 5.717963218688965\n",
            "Epoch: 5, Batch: 101, D_Loss: 0.13201773911714554, G_Loss: 6.514206886291504\n",
            "Epoch: 5, Batch: 201, D_Loss: 0.06446805037558079, G_Loss: 2.893305778503418\n",
            "Epoch: 5, Batch: 301, D_Loss: 0.13023269921541214, G_Loss: 7.591945648193359\n",
            "Epoch: 5, Batch: 401, D_Loss: 0.2771093584597111, G_Loss: 4.849626541137695\n",
            "Epoch: 5, Batch: 501, D_Loss: 0.013484355062246323, G_Loss: 7.54946756362915\n",
            "Epoch: 5, Batch: 601, D_Loss: 0.08764652162790298, G_Loss: 4.803228378295898\n",
            "Epoch: 5, Batch: 701, D_Loss: 0.38364478200674057, G_Loss: 4.879153728485107\n",
            "Epoch: 5, Batch: 801, D_Loss: 0.034035255666822195, G_Loss: 6.4552412033081055\n",
            "Epoch: 5, Batch: 901, D_Loss: 0.1280272615258582, G_Loss: 8.222946166992188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequence to Sequence Model for Translation"
      ],
      "metadata": {
        "id": "dx9nFdFGHgyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "QLcGiRq0HgiG"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an encoder-decoder model\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = nn.RNN(input_dim, hidden_dim, batch_first=True)\n",
        "        self.decoder = nn.RNN(hidden_dim, output_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encode the input sequence\n",
        "        _, hidden = self.encoder(x)  # hidden: [1, batch_size, hidden_dim]\n",
        "\n",
        "        # Repeat hidden state for all time steps\n",
        "        hidden_repeated = hidden.repeat(x.size(1), 1, 1).permute(1, 0, 2)\n",
        "\n",
        "        # Decode using the repeated hidden state\n",
        "        output, _ = self.decoder(hidden_repeated)\n",
        "        return output\n",
        "\n",
        "# Create some dummy data\n",
        "x_train = torch.randn(100, 10, 5)  # 100 sequences of length 10 with 5 features\n",
        "y_train = torch.randn(100, 10, 3)  # 100 sequences of length 10 with 3 features\n",
        "\n",
        "# Instantiate the model, define loss and optimizer\n",
        "input_dim = 5\n",
        "hidden_dim = 20\n",
        "output_dim = 3\n",
        "model = Seq2Seq(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "\n",
        "    # Forward pass\n",
        "    y_pred = model(x_train)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fswz0WW_HsBk",
        "outputId": "134b94a9-ca8c-4f9c-fa3d-9c1d870f3593"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 1.3762903213500977\n",
            "Epoch: 2, Loss: 1.238774299621582\n",
            "Epoch: 3, Loss: 1.1877046823501587\n",
            "Epoch: 4, Loss: 1.148733377456665\n",
            "Epoch: 5, Loss: 1.0890756845474243\n",
            "Epoch: 6, Loss: 1.0568042993545532\n",
            "Epoch: 7, Loss: 1.0537418127059937\n",
            "Epoch: 8, Loss: 1.0509737730026245\n",
            "Epoch: 9, Loss: 1.0434114933013916\n",
            "Epoch: 10, Loss: 1.0383517742156982\n",
            "Epoch: 11, Loss: 1.0367317199707031\n",
            "Epoch: 12, Loss: 1.0341196060180664\n",
            "Epoch: 13, Loss: 1.0289456844329834\n",
            "Epoch: 14, Loss: 1.0230926275253296\n",
            "Epoch: 15, Loss: 1.0184237957000732\n",
            "Epoch: 16, Loss: 1.015229344367981\n",
            "Epoch: 17, Loss: 1.013109564781189\n",
            "Epoch: 18, Loss: 1.0117244720458984\n",
            "Epoch: 19, Loss: 1.0106925964355469\n",
            "Epoch: 20, Loss: 1.0094670057296753\n",
            "Epoch: 21, Loss: 1.0076595544815063\n",
            "Epoch: 22, Loss: 1.0054506063461304\n",
            "Epoch: 23, Loss: 1.0034857988357544\n",
            "Epoch: 24, Loss: 1.0022796392440796\n",
            "Epoch: 25, Loss: 1.0017480850219727\n",
            "Epoch: 26, Loss: 1.0013526678085327\n",
            "Epoch: 27, Loss: 1.0006507635116577\n",
            "Epoch: 28, Loss: 0.9996250867843628\n",
            "Epoch: 29, Loss: 0.9985241889953613\n",
            "Epoch: 30, Loss: 0.9975176453590393\n",
            "Epoch: 31, Loss: 0.996573269367218\n",
            "Epoch: 32, Loss: 0.9956163167953491\n",
            "Epoch: 33, Loss: 0.9946951270103455\n",
            "Epoch: 34, Loss: 0.9939391016960144\n",
            "Epoch: 35, Loss: 0.9934088587760925\n",
            "Epoch: 36, Loss: 0.9930429458618164\n",
            "Epoch: 37, Loss: 0.9927257299423218\n",
            "Epoch: 38, Loss: 0.9923650026321411\n",
            "Epoch: 39, Loss: 0.9919032454490662\n",
            "Epoch: 40, Loss: 0.9913074374198914\n",
            "Epoch: 41, Loss: 0.9905989766120911\n",
            "Epoch: 42, Loss: 0.9898738861083984\n",
            "Epoch: 43, Loss: 0.9892442226409912\n",
            "Epoch: 44, Loss: 0.9887374639511108\n",
            "Epoch: 45, Loss: 0.9882766008377075\n",
            "Epoch: 46, Loss: 0.9877700209617615\n",
            "Epoch: 47, Loss: 0.987201988697052\n",
            "Epoch: 48, Loss: 0.9866191148757935\n",
            "Epoch: 49, Loss: 0.986045241355896\n",
            "Epoch: 50, Loss: 0.9854461550712585\n",
            "Epoch: 51, Loss: 0.9847829341888428\n",
            "Epoch: 52, Loss: 0.9840749502182007\n",
            "Epoch: 53, Loss: 0.9833812117576599\n",
            "Epoch: 54, Loss: 0.9827325940132141\n",
            "Epoch: 55, Loss: 0.9821067452430725\n",
            "Epoch: 56, Loss: 0.9814682006835938\n",
            "Epoch: 57, Loss: 0.9808026552200317\n",
            "Epoch: 58, Loss: 0.980106770992279\n",
            "Epoch: 59, Loss: 0.9793692231178284\n",
            "Epoch: 60, Loss: 0.9785848259925842\n",
            "Epoch: 61, Loss: 0.9777705669403076\n",
            "Epoch: 62, Loss: 0.9769471287727356\n",
            "Epoch: 63, Loss: 0.9761136770248413\n",
            "Epoch: 64, Loss: 0.97525954246521\n",
            "Epoch: 65, Loss: 0.9743854999542236\n",
            "Epoch: 66, Loss: 0.9734969139099121\n",
            "Epoch: 67, Loss: 0.9725813865661621\n",
            "Epoch: 68, Loss: 0.9716198444366455\n",
            "Epoch: 69, Loss: 0.9706146121025085\n",
            "Epoch: 70, Loss: 0.9695871472358704\n",
            "Epoch: 71, Loss: 0.9685521125793457\n",
            "Epoch: 72, Loss: 0.9675057530403137\n",
            "Epoch: 73, Loss: 0.9664420485496521\n",
            "Epoch: 74, Loss: 0.9653604626655579\n",
            "Epoch: 75, Loss: 0.9642633199691772\n",
            "Epoch: 76, Loss: 0.9631581902503967\n",
            "Epoch: 77, Loss: 0.9620572328567505\n",
            "Epoch: 78, Loss: 0.9609680771827698\n",
            "Epoch: 79, Loss: 0.9598900675773621\n",
            "Epoch: 80, Loss: 0.9588227272033691\n",
            "Epoch: 81, Loss: 0.9577726125717163\n",
            "Epoch: 82, Loss: 0.9567446112632751\n",
            "Epoch: 83, Loss: 0.9557403326034546\n",
            "Epoch: 84, Loss: 0.9547634124755859\n",
            "Epoch: 85, Loss: 0.9538130164146423\n",
            "Epoch: 86, Loss: 0.952879786491394\n",
            "Epoch: 87, Loss: 0.9519559741020203\n",
            "Epoch: 88, Loss: 0.9510393142700195\n",
            "Epoch: 89, Loss: 0.950128436088562\n",
            "Epoch: 90, Loss: 0.949219822883606\n",
            "Epoch: 91, Loss: 0.9483127593994141\n",
            "Epoch: 92, Loss: 0.9474064111709595\n",
            "Epoch: 93, Loss: 0.9464985132217407\n",
            "Epoch: 94, Loss: 0.9455904960632324\n",
            "Epoch: 95, Loss: 0.9446877241134644\n",
            "Epoch: 96, Loss: 0.9437947869300842\n",
            "Epoch: 97, Loss: 0.9429153800010681\n",
            "Epoch: 98, Loss: 0.9420537352561951\n",
            "Epoch: 99, Loss: 0.9412128329277039\n",
            "Epoch: 100, Loss: 0.9403937458992004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L780kEJ9JNpw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}